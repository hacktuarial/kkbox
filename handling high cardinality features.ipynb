{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two ways of estimating user- and item- bias factors\n",
    "1. One hot encode them and put them into an xgboost model with some other features\n",
    "2. Use `diamond` to fit a crossed random-effects model, then put these predictions into an xgboost model with the same set of other features\n",
    "\n",
    "These other features include\n",
    "* genre encoding: one song can be in multiple genres\n",
    "* Categorical features\n",
    "    * source_system_tab\n",
    "    * source_screen_name\n",
    "    * source_type \n",
    "    * artist_name\n",
    "    * composer\n",
    "    * lyricist\n",
    "    * language\n",
    "    * city\n",
    "    * gender\n",
    "    * registered_via\n",
    "* Numeric features\n",
    "    * song_length\n",
    "    * bd\n",
    "    * registration_init_time\n",
    "    * expiration_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "node_exists": true,
    "node_name": "62C5A21A75D640F99AF43C267E16D48F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothysweetser/python/virtualenv/work3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from diamond.glms.logistic import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import utils\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s',\n",
    "                   level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [nodebook](http://github.com/stitchfix/nodebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "node_exists": true,
    "node_name": "8C4911A54B8C488988DAF4030E93A286"
   },
   "outputs": [],
   "source": [
    "def id_to_index(ids):\n",
    "    \" return a dict like {id: idx} \"\n",
    "    unique_ids = set(ids)\n",
    "    return dict(zip(unique_ids, np.arange(0, len(unique_ids))))\n",
    "\n",
    "def encode_categoricals(df, cat_features, id_col):\n",
    "    \"\"\"\n",
    "    one hot encode categorical features. modifies `df` in-place\n",
    "    \"\"\"\n",
    "    idx = id_col + 'x'\n",
    "    for x in cat_features:\n",
    "        df[x] = df[x].astype(str).fillna('unknown')\n",
    "    id_map = id_to_index(df[id_col])\n",
    "    df[idx] = df[id_col].apply(lambda x: id_map[x])\n",
    "    df = df[cat_features + [idx]].\\\n",
    "        sort_values(idx)\n",
    "    X = DictVectorizer().fit_transform(df.T.to_dict().values())\n",
    "    return X.tocsr(), id_map\n",
    "\n",
    "def encode_genres(song_map):\n",
    "    \" this is a many-hot encoding of song to genre \"\n",
    "    df_genres = df_songs['genre_ids'].apply(lambda s: pd.Series(str(s).split('|')))\n",
    "    df_genres['song_idx'] = df_songs['song_id'].apply(lambda x: song_map[x])\n",
    "    df_genres2 = pd.melt(df_genres, 'song_idx', value_name='genre').\\\n",
    "        drop('variable', axis=1).\\\n",
    "        dropna().\\\n",
    "        sort_values('song_idx')\n",
    "    genre_map = id_to_index(df_genres2['genre'])\n",
    "    df_genres2['genre_idx'] = df_genres2['genre'].apply(lambda g: genre_map[g])\n",
    "    X_genres = sparse.coo_matrix((np.ones(len(df_genres2)),\n",
    "                                 (df_genres2['song_idx'], df_genres2['genre_idx'])))\n",
    "    return X_genres.tocsr(), genre_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "node_exists": false,
    "node_name": "AF53E0C74AF04C84B93F1F32FCDD0DEA"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/raw/train.csv')\n",
    "df_songs = pd.read_csv('data/raw/songs.csv')\n",
    "df_members = pd.read_csv('data/raw/members.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create design matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "node_exists": false,
    "node_name": "2CCB56F13F754286990A1D187D1A6989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296320, 663127)\n",
      "CPU times: user 3min 12s, sys: 3.21 s, total: 3min 15s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_songs, song_map = encode_categoricals(df_songs, \n",
    "                              ['artist_name', 'composer', 'lyricist', 'language'],\n",
    "                              'song_id')\n",
    "assert X_songs.shape[0] == len(df_songs)\n",
    "print(X_songs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "node_exists": false,
    "node_name": "A520E2D92BB74B35B56928E4040A75BC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34403, 31)\n",
      "CPU times: user 2.38 s, sys: 53.7 ms, total: 2.43 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_members, member_map = encode_categoricals(df_members,\n",
    "                                ['city', 'gender', 'registered_via'],\n",
    "                                'msno')\n",
    "assert X_members.shape[0] == len(df_members)\n",
    "print(X_members.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDs: benchmark for diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "node_exists": false,
    "node_name": "F76EA1E9F51149218E4920B5A55FCB9F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 541 ms, sys: 60.4 ms, total: 601 ms\n",
      "Wall time: 601 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_member_ids = sparse.coo_matrix((np.ones(len(df_members)),\n",
    "                                  (df_members['msnox'], df_members['msnox']))).tocsr()\n",
    "X_song_ids = sparse.coo_matrix((np.ones(len(df_songs)),\n",
    "                                  (df_songs['song_idx'], df_songs['song_idx']))).tocsr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "node_exists": false,
    "node_name": "A629DF3281A7455D9CBE6846E69D1561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 5s, sys: 17.2 s, total: 7min 23s\n",
      "Wall time: 7min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_genres, genre_map = encode_genres(song_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source features\n",
    "Thanks to [Ritchie Ng](http://www.ritchieng.com/machinelearning-one-hot-encoding/) for guidance on using One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.9 s, sys: 2.2 s, total: 42.1 s\n",
      "Wall time: 42.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source_features = ['source_system_tab', 'source_screen_name', 'source_type']\n",
    "LE, OHE = LabelEncoder(), OneHotEncoder()\n",
    "\n",
    "X_source = OHE.fit_transform(\n",
    "    df_train[source_features].\\\n",
    "    fillna('unknown').\\\n",
    "    apply(LE.fit_transform)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train diamond model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a train/test split for this and subsequent modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_val = df_train.iloc[utils.TTS:, :]\n",
    "df_train = df_train.iloc[:utils.TTS, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "node_exists": false,
    "node_name": "1A3ED1DF79384612BD301EC64F2C6107"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-22 14:46:10,034 INFO:creating main design matrix\n",
      "2017-10-22 14:46:12,057 INFO:creating song_id design matrix\n",
      "2017-10-22 14:46:23,091 INFO:creating msno design matrix\n",
      "2017-10-22 14:46:30,198 INFO:creating covariance matrix\n",
      "2017-10-22 14:46:30,202 INFO:creating Hessians\n",
      "2017-10-22 14:46:30,297 INFO:creating H_inter for song_id\n",
      "2017-10-22 14:46:31,637 INFO:time elapsed: 53.8\n",
      "2017-10-22 14:46:31,638 INFO:blocks inverted: 0 of 287748\n",
      "2017-10-22 14:46:57,719 INFO:time elapsed: 79.9\n",
      "2017-10-22 14:46:57,720 INFO:blocks inverted: 100000 of 287748\n",
      "2017-10-22 14:47:23,817 INFO:time elapsed: 106.0\n",
      "2017-10-22 14:47:23,817 INFO:blocks inverted: 200000 of 287748\n",
      "2017-10-22 14:47:46,768 INFO:creating H_invs\n",
      "2017-10-22 14:47:47,614 INFO:creating H_inter for msno\n",
      "2017-10-22 14:47:48,173 INFO:time elapsed: 130.4\n",
      "2017-10-22 14:47:48,174 INFO:blocks inverted: 0 of 26411\n",
      "2017-10-22 14:47:55,106 INFO:creating H_invs\n",
      "2017-10-22 14:54:02,598 INFO:extracting coefficients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 26s, sys: 1min 45s, total: 9min 12s\n",
      "Wall time: 8min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "formula = 'target ~ 1 + (1|song_id) + (1|msno)'\n",
    "\n",
    "priors = pd.DataFrame({'group': ['song_id', 'msno'],\n",
    "                       'var1': ['intercept'] * 2,\n",
    "                       'var2': [np.nan] * 2,\n",
    "                       # fit on a sample of data in R/lme4\n",
    "                       'vcov': [0.00845, 0.07268]})\n",
    "diamond = LogisticRegression(df_train, priors)\n",
    "effects = diamond.fit(formula, tol=1e-5, verbose=False, max_its=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "node_exists": false,
    "node_name": "465F9D3B491745CDB04E4655F9FABA00"
   },
   "outputs": [],
   "source": [
    "with open('models/diamond.p', 'wb') as ff:\n",
    "    pickle.dump(diamond, ff)\n",
    "\n",
    "df_train['diamond_pred'] = diamond.predict(df_train)\n",
    "df_val['diamond_pred'] = diamond.predict(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.drop(['row_index', 'intercept'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "node_exists": false,
    "node_name": "6CAE687BA4624F6DA6A63781B66EA811"
   },
   "outputs": [],
   "source": [
    "def merge_it_all_together(df, use_diamond):\n",
    "    \"\"\"\n",
    "    Merge member, song, and source data together\n",
    "    Return (X, y) tuple\n",
    "    This makes a _copy_ of df\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info('merging in song info')\n",
    "    df = pd.merge(df.drop(source_features, axis=1),\n",
    "                  df_songs[['song_id', 'song_idx', 'song_length']],\n",
    "                  # there are 80 interactions with unknown songs in the training set\n",
    "                  # remove them!\n",
    "                  'inner',\n",
    "                  'song_id')\n",
    "    logging.info('merging in member info')\n",
    "    df = pd.merge(df, df_members[['msno', 'msnox',\n",
    "                                  'registration_init_time', 'expiration_date', 'bd']], 'left', 'msno')\n",
    "    n_nulls = df.isnull().sum()\n",
    "    assert n_nulls.sum() == 0, n_nulls\n",
    "    logging.info('there are no nulls')\n",
    "    \n",
    "    numeric_features = ['song_length', 'registration_init_time', 'expiration_date', 'bd']\n",
    "    X_numeric = df[numeric_features].as_matrix()\n",
    "    member_idx = df['msnox']\n",
    "    song_idx = df['song_idx']\n",
    "    del df  # free up the memory\n",
    "    \n",
    "    if use_diamond:\n",
    "        logging.info('using diamond predictions')\n",
    "        numeric_features.append('diamond_prediction')\n",
    "        matrix_list = []\n",
    "    else:\n",
    "        logging.info('using one-hot encoding of member, song ids')\n",
    "        matrix_list = [X_member_ids[member_idx, :],\n",
    "                       X_song_ids[song_idx, :]]\n",
    "    \n",
    "    logging.info('adding numeric feature matrix')\n",
    "    matrix_list.append(X_numeric)\n",
    "    logging.info('creating song matrix')\n",
    "    matrix_list.append(X_songs[song_idx, :])\n",
    "    logging.info('creating genre matrix')\n",
    "    matrix_list.append(X_genres[sonx_idx, :])\n",
    "    logging.info('creating member matrix')\n",
    "    matrix_list.append(X_members[member_idx, :])\n",
    "\n",
    "    logging.info('concatenating matrices')\n",
    "    X = sparse.hstack(matrix_list)\n",
    "    \n",
    "    y = df['target']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "node_exists": false,
    "node_name": "B09D01850486435993B28EF8638E8392"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-22 14:54:35,851 INFO:merging in song info\n",
      "2017-10-22 14:54:38,249 INFO:merging in member info\n",
      "2017-10-22 14:54:40,137 INFO:there are no nulls\n",
      "2017-10-22 14:54:40,159 INFO:using diamond predictions\n",
      "2017-10-22 14:54:40,160 INFO:adding numeric feature matrix\n",
      "2017-10-22 14:54:40,161 INFO:creating song matrix\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = merge_it_all_together(df_val, use_diamond=True)\n",
    "del df_val\n",
    "D_val = xgb.DMatrix(sparse.hstack([X_val, X_source[utils.TTS:, :]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "node_exists": false,
    "node_name": "B09D01850486435993B28EF8638E8392"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, y_train = merge_it_all_together(df_train, use_diamond=False)\n",
    "D_train = xgb.DMatrix(sparse.hstack([X_train, X_source[:utils.TTS, :]]),\n",
    "                      y_train)\n",
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train xgboost models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Use 5-fold CV and grid search to estimate hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "node_exists": false,
    "node_name": "19069C847FFB4940AD5EDAC403CE1EE3"
   },
   "outputs": [],
   "source": [
    "# df_train model, evaluate and make predictions\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.75\n",
    "params['max_depth'] = 5\n",
    "params['silent'] = 1\n",
    "params['eval_metric'] = 'auc'\n",
    "MAX_ITS = 200\n",
    "\n",
    "model_without_diamond = xgb.train(params, D_train, MAX_ITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a similar model, but using diamond's predictions instead of one-hot-encoded song and member id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = merge_it_all_together(df_train, use_diamond=True)\n",
    "X_train = sparse.hstack([X_train, X_source[:utils.TTS, :]])\n",
    "D_train = xgb.DMatrix(X_train, y_train)\n",
    "del X_train, y_train\n",
    "X_val, y_val = merge_it_all_together(df_val, use_diamond=True)\n",
    "X_val = sparse.hstack([X_val, X_val[utils.TTS:, :]])\n",
    "D_val = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_with_diamond = xgb.train(params, D_train, MAX_ITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc(score(df_val['target']),\n",
    "        model_without_diamond.predict(D_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc(score(df_val['target']),\n",
    "        model_with_diamond.predict(D_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
